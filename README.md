# A critical analysis of LLM-based code generation: Adoption and security assessment  #
Master's Thesis submitted to obtain the degree of Master of Science in Electronics and ICT Engineering Technology 

by Lowie Peelaers and Pia LÃ¶we

## Abstract: ##
Latest technology advancements enable rapid improvements of Large Language Models (LLMs). The field of code assistants based on these LLMs is therefore expanding every day, permitting developers to meet the higher demand of productivity and efficiency. The security of the generated code by code assistants is often critical because of vulnerable training data. The research field regarding these concerns is rather limited. We came across several studies investigating code generated by GitHub Copilot. We have encountered a gap in the literature regarding research on code generation by ChatGPT. In this study, we empirically analyzed the functionality and security of LLM-based code generation. We prompted ChatGPT and GitHub Copilot with a combination of text and code pieces, and critically analyzed their responses including text and code. We designed the prompts to reflect real-world prompting scenarios on the level of full implementations, code completions, and error corrections. Our findings revealed serious limitations when it comes to error corrections. We could observe that ChatGPT contrary to GitHub Copilot was not able to correct errors when the error code was not provided. Furthermore, implied our observations a diverse response behavior of ChatGPT, among other factors impacting the code quality and security. Analysis of both code assistants led us to the conclusion that developers must critically scrutinize LLM-based code-generations.

## Repository content: ##
There are two directories:
- Flask 
- Spring

Each directory contains the exact conversations between the authors and the chat bots that were conducted for the purpose of this study. Additionally, the directories can contain the source code, additional information about execution results, outcomes of the vulnerability scanners, or conversations to let the chat bots fix errors. 